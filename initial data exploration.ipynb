{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e841c3c0-0313-409d-bb15-74ce08ceb43c",
   "metadata": {},
   "source": [
    "# StreamingHistory0 Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cfd4944-874a-422c-afcf-6bc02d56600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "from operator import itemgetter\n",
    "from pprint import pprint\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d2d1441-1d8b-4795-b1b4-88a620caf124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonatan\\code\\vis_project\\venv\\lib\\site-packages\\pandas\\core\\generic.py:5516: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/StreamingHistory0.json\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.loads(f.read())\n",
    "\n",
    "_df = pd.DataFrame(data)\n",
    "skipped = _df[_df.msPlayed <= 10_000]\n",
    "df = _df[_df.msPlayed > 10_000]\n",
    "# df.endTime = df.endTime.apply(lambda dt: datetime.strptime(dt, \"%Y-%m-%d %H:%M\"))\n",
    "df.endTime = pd.to_datetime(df.endTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51c11c4a-4b75-4aa5-a93d-5f1271f202a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trackName\n",
       "Like a Rolling Stone                                                       (1.0, 3)\n",
       "Yuve Yuve Yu                                                               (1.0, 3)\n",
       "Happier Than Ever                                                          (1.0, 3)\n",
       "Heartbreaks From The Black Of The Abyss                                    (1.0, 3)\n",
       "Shuffle                                                                    (1.0, 2)\n",
       "This Beard Is for Siobhan                                                  (1.0, 2)\n",
       "Male Fantasy                                                               (1.0, 2)\n",
       "Waiting For A Train - Instrumental                                         (1.0, 2)\n",
       "Mideast Vacation                                                           (1.0, 2)\n",
       "Tonight I'll Be Staying Here With You - Recorded at Spotify Studios NYC    (1.0, 2)\n",
       "Castaway                                                                   (1.0, 2)\n",
       "Dear McCracken                                                             (1.0, 2)\n",
       "My Body Is a Cage                                                          (1.0, 2)\n",
       "The Beat                                                                   (1.0, 2)\n",
       "Brown Eyed Girl                                                            (1.0, 2)\n",
       "Burning                                                                    (1.0, 2)\n",
       "Swans and the Swimming                                                     (1.0, 2)\n",
       "Hopopono                                                                   (1.0, 2)\n",
       "Cold Meteor Showers                                                        (1.0, 2)\n",
       "Say My Name                                                                (1.0, 2)\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df.groupby(\"trackName\").apply(lambda df: (np.sum(df.msPlayed <= 10_000) / len(df), len(df))).sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239f7c7d-f18d-484a-897d-dca6d0ce0898",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.artistName.value_counts().head(2))\n",
    "print(df.trackName.value_counts().head(2))\n",
    "df[[\"artistName\", \"trackName\"]].value_counts().head(5)\n",
    "\n",
    "times = df.endTime.dt.hour.value_counts()\n",
    "times = times.reindex(range(24), fill_value=0)\n",
    "times.sort_index().plot(kind=\"bar\")\n",
    "plt.show()\n",
    "\n",
    "weekdays = df.endTime.dt.dayofweek.value_counts()\n",
    "weekdays = times.reindex(range(7), fill_value=0).sort_index()\n",
    "weekdays.index = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n",
    "weekdays.plot(kind=\"bar\")\n",
    "plt.show()\n",
    "\n",
    "months = df['endTime'] - pd.offsets.MonthBegin(0)\n",
    "months = months.dt.round('d')\n",
    "months = months.value_counts()\n",
    "months = months.sort_index()\n",
    "months.plot(kind=\"bar\")\n",
    "plt.show()\n",
    "\n",
    "# Below is not correct\n",
    "weeks = df['endTime'] - pd.to_timedelta(df['endTime'].dt.dayofweek, unit='d')\n",
    "weeks = weeks.dt.round('d')\n",
    "weeks = weeks.value_counts()\n",
    "weeks = weeks.sort_index()\n",
    "weeks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4969c5-408d-4252-a21d-c9c9eec01bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "oauth_token = \"Bearer BQAbeiv-i2bwyloeoj6gWNcNy2ca9XqvyuX5hi-GNrSJrEV4UFWK5M9z-ypghlM0_qPRwi6AfFhWMlDyIUnE_6oRnWpYefHNyBprpxqtURpvWvvyoUDp2vMJuQG7kF7nRNgCQ-F4Mkk27q9s_NRXyQhGF_1bPaYcRGU-uCjesV_Zp3U0Ill-40BSBjNirWQVUbGWvHV6FElCgNUEO98SCD9GlSmHblQ6xFS0rFAYr4KSgsMurWy3CCfMAbZ4T6YabqwAlRn_sxJfRPneMAI\"\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": oauth_token\n",
    "}\n",
    "\n",
    "def get_track_data_by_name(artist_name, track_name):\n",
    "    def normalize_str(s):\n",
    "        return re.sub(\"\\'`Â´\", \"\", s.lower())\n",
    "    \n",
    "    def search(params):\n",
    "        resp = requests.get(endpoint, headers=headers, params=params)\n",
    "        data = json.loads(resp.text)\n",
    "        tracks = data['tracks']['items']\n",
    "        found_tracks.update(\", \".join(a[\"name\"] for a in track[\"artists\"]) + \" - \" + track[\"name\"]\n",
    "                            for track in tracks)\n",
    "        return next(track for track in tracks\n",
    "                       if normalize_str(track['name']) == normalize_str(track_name)\n",
    "                       and artist_name in [a[\"name\"] for a in track[\"artists\"]])\n",
    "    \n",
    "    found_tracks = set()\n",
    "    endpoint = \"https://api.spotify.com/v1/search\"\n",
    "    params = {\"q\": track_name + \" \" + artist_name, \"type\": \"track\", \"limit\": 20}\n",
    "    try:\n",
    "        try:\n",
    "            return search(params)\n",
    "        except StopIteration:\n",
    "            return search(params | {\"q\": track_name})\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(resp.text)\n",
    "        raise e\n",
    "    except KeyError as e:\n",
    "        print(\"bad data:\")\n",
    "        pprint(data)\n",
    "        raise e\n",
    "    except StopIteration:        \n",
    "        print(f\"unable to find: {artist_name} - {track_name}\")\n",
    "        print(\"found:\", found_tracks, end=\"\\n\\n\")\n",
    "    \n",
    "\n",
    "def get_artist_data_by_name(artist_name):\n",
    "    endpoint = \"https://api.spotify.com/v1/search\"\n",
    "    params = {\"q\": artist_name, \"type\": \"artist\", \"limit\": 10}\n",
    "    resp = requests.get(endpoint, headers=headers, params=params)\n",
    "    data = json.loads(resp.text)\n",
    "    artist_data = [artist for artist in data['artists']['items'] if artist['name'] == artist_name]\n",
    "    ranked_by_popularity = sorted(artist_data, key=lambda a: a['followers']['total'], reverse=True)\n",
    "    \n",
    "    if artist_data:\n",
    "        return ranked_by_popularity[0]\n",
    "    \n",
    "    print(\"unable to find\", artist_name)\n",
    "\n",
    "def get_related_artists(artist_id):\n",
    "    endpoint = f\"https://api.spotify.com/v1/artists/{artist_id}/related-artists\"\n",
    "    resp = requests.get(endpoint, headers=headers)\n",
    "    \n",
    "    if resp.status_code == 200:\n",
    "        return json.loads(resp.text)['artists']\n",
    "    \n",
    "    print(\"Could not find\", artist_id)\n",
    "    \n",
    "#get_artist_data_by_name(\"Muse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2b313d76-2a9a-45e2-8bc1-c789ba534864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endTime</th>\n",
       "      <th>artistName</th>\n",
       "      <th>trackName</th>\n",
       "      <th>msPlayed</th>\n",
       "      <th>artist_genres</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_popularity</th>\n",
       "      <th>track_duration_ms</th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2021-02-26 20:50</td>\n",
       "      <td>Dirty Projectors</td>\n",
       "      <td>Cannibal Resource</td>\n",
       "      <td>1590</td>\n",
       "      <td>[art pop, brooklyn indie, experimental pop, fr...</td>\n",
       "      <td>5VF0YkVLeVD4ytyiyVSIiF</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             endTime        artistName          trackName  msPlayed  \\\n",
       "43  2021-02-26 20:50  Dirty Projectors  Cannibal Resource      1590   \n",
       "\n",
       "                                        artist_genres               artist_id  \\\n",
       "43  [art pop, brooklyn indie, experimental pop, fr...  5VF0YkVLeVD4ytyiyVSIiF   \n",
       "\n",
       "    artist_popularity track_duration_ms track_id track_popularity  \n",
       "43                 47               NaN      NaN              NaN  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "def scrape_track_data():\n",
    "    # Uniquely identify tracks by artist_name + track_name\n",
    "    # Since these are stored as a tuple, and json doesn't support tuple keys, extra work has to be done when reading and writing.\n",
    "    # Spotify has unique ids for all tracks, but our local data doesn't. TODO: Integrate track and artist id into streaming history\n",
    "    try:\n",
    "        with open('data/track_data.json', mode='r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            data = {literal_eval(k): v for k, v in data.items()}\n",
    "    except FileNotFoundError:\n",
    "        data = {}\n",
    "        \n",
    "    known_tracks = pd.Series(data.keys())\n",
    "    all_tracks = pd.Series(df[[\"artistName\", \"trackName\"]].agg(tuple, axis=1).unique())\n",
    "    unknown_tracks = all_tracks[~all_tracks.isin(known_tracks)]\n",
    "    \n",
    "    if False:  # retrieve missing entries from spotify API\n",
    "        try:\n",
    "            for artist, track in unknown_tracks:\n",
    "                result = get_track_data_by_name(artist, track)\n",
    "                if result:\n",
    "                    data[(artist, track)] = result\n",
    "        finally:\n",
    "            with open('data/track_data.json', mode='w+', encoding='utf-8') as f:\n",
    "                json.dump({str(k): v for k,v in data.items()}, f)\n",
    "\n",
    "    return data\n",
    "\n",
    "def scrape_artist_data():\n",
    "    try:\n",
    "        with open('data/artist_data.json', mode='r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        data = []\n",
    "        \n",
    "    known_artists = pd.Series([artist['name'] for artist in data if artist is not None])\n",
    "    all_artists = pd.Series(df.artistName.unique())\n",
    "    unknown_artists = all_artists[~all_artists.isin(known_artists)]\n",
    "    \n",
    "    if False:  # retrieve missing entries from spotify API\n",
    "        try:\n",
    "            for artist in unknown_artists:\n",
    "                result = get_artist_data_by_name(artist)\n",
    "                if result:\n",
    "                    data.append(result)\n",
    "        finally:\n",
    "            with open('data/artist_data.json', mode='w+', encoding='utf-8') as f:\n",
    "                json.dump(data, f)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def scrape_related_artists(artist_ids):\n",
    "    try:\n",
    "        with open('data/related_artist_data.json', mode='r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        data = {}\n",
    "    \n",
    "    known_related = pd.Series(data.keys())\n",
    "    missing_related = artist_ids[~artist_ids.isin(known_related)]\n",
    "    \n",
    "    if False:  # retrieve missing entries from spotify API\n",
    "        try:\n",
    "            for artist_id in missing_related:\n",
    "                if (result := get_related_artists(artist_id)):\n",
    "                    data[artist_id] = result\n",
    "        finally:\n",
    "            with open('data/related_artist_data.json', mode='w+', encoding='utf-8') as f:\n",
    "                json.dump(data, f)\n",
    "\n",
    "    return data\n",
    "\n",
    "def read_audio_features(track_ids):\n",
    "    try:\n",
    "        with open('data/track_feature_data.json', mode='r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        data = {}\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "artist_data = pd.DataFrame(scrape_artist_data())\n",
    "artist_data.columns = artist_data.columns.map(lambda s: \"artist_\" + s)\n",
    "\n",
    "track_data = pd.DataFrame(scrape_track_data()).transpose()\n",
    "track_data.columns = track_data.columns.map(lambda s: s if s.startswith(\"track_\") else \"track_\" + s)\n",
    "\n",
    "related_artists = pd.Series(scrape_related_artists(artist_data.artist_id), name=\"id\")\n",
    "track_features = pd.DataFrame(read_audio_features(track_data[\"track_id\"]))\n",
    "\n",
    "merged = pd.merge(_df, artist_data, left_on='artistName', right_on='artist_name', how='inner')\n",
    "\n",
    "merged = pd.merge(merged, track_data, left_on=[\"artistName\", \"trackName\"], right_index=True, how=\"left\")\n",
    "\n",
    "if False:\n",
    "    keep_columns = list(df.columns) + [\"artist_genres\", \"artist_id\", \"artist_popularity\", \"track_duration_ms\", \"track_id\", \"track_popularity\"]\n",
    "    write_df = merged[keep_columns]\n",
    "    json_str = write_df.to_json(orient=\"records\")\n",
    "    with open(\"data/merged_history.json\", mode=\"w+\", encoding=\"utf-8\") as f:\n",
    "        f.write(json_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fb5388-faab-45a9-940c-d67db633ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_series(series):\n",
    "    return series.apply(pd.Series).stack().reset_index(drop=True)\n",
    "\n",
    "def genre_count(df):\n",
    "    return flatten_series(df.genres).value_counts()\n",
    "\n",
    "def weighted_genre_count(df):\n",
    "    all_genres = flatten_series(df.genres).unique()\n",
    "    \n",
    "    genre_counts = {genre: 0 for genre in all_genres}\n",
    "    for genres in df.genres:\n",
    "        for g in genres:\n",
    "            genre_counts[g] += 1/len(genres)\n",
    "\n",
    "    genre_counts = {\"genre\": genre_counts.keys(), \"popularity\": genre_counts.values()}\n",
    "    genre_count_df = pd.DataFrame(genre_counts).sort_values(by=\"popularity\", ascending=False).reset_index(drop=True)\n",
    "        \n",
    "    return genre_count_df\n",
    "    \n",
    "    #exploded = df.genres.explode()\n",
    "    #return (exploded.groupby(level=0).transform('count').groupby(exploded).sum()).sort_values(ascending=False)\n",
    "    \n",
    "    \n",
    "def genre_adj_list(genre_lists):  # genre_lists is a nested list, each item being the genres of an artist\n",
    "    genres = flatten_series(genre_lists).unique()\n",
    "    num_genres = len(genres)\n",
    "    adjacency_list = {g: [] for g in genres}\n",
    "    for gs in genre_lists:\n",
    "        for g in gs:\n",
    "            adjacency_list[g] += gs\n",
    "    \n",
    "    for k, v in adjacency_list.items():\n",
    "        adjacency_list[k] = [g for g in v if g != k]\n",
    "        \n",
    "    df = pd.DataFrame({\"genre\": adjacency_list.keys(), \"neighbors\": adjacency_list.values()})\n",
    "    return df\n",
    "    \n",
    "    \n",
    "def genre_adj_matrix(genre_lists):\n",
    "    genres = flatten_series(genre_lists).unique()\n",
    "    num_genres = len(genres)\n",
    "    \n",
    "    base_matrix = np.zeros((num_genres, num_genres))\n",
    "    adj_matrix = pd.DataFrame(base_matrix, columns=genres, index=genres)\n",
    "    \n",
    "    \n",
    "    for gs in genre_lists:\n",
    "        for a, g in combinations(gs, 2):\n",
    "            adj_matrix[a][g] += 1\n",
    "            \n",
    "    return adj_matrix\n",
    "    \n",
    "    \n",
    "def co_occurrence_score(occurrences):\n",
    "    # note: not correct\n",
    "    adj_matrix = genre_adj_matrix(occurrences)\n",
    "    flattened_genres = flatten_series(genres)\n",
    "    total_occurrences = flattened_genres.groupby(flattened_genres).count()\n",
    "    return adj_matrix.transpose() / total_occurrences\n",
    "        \n",
    "\n",
    "# genre_count(artist_data)\n",
    "# weighted_genre_count(artist_data).head(20)\n",
    "genres = artist_data.genres\n",
    "adj_matrix = genre_adj_matrix(genres)\n",
    "adj_list = genre_adj_list(genres)\n",
    "\n",
    "co_occs = co_occurrence_score(genres)\n",
    "co_occs = co_occs[co_occs < 1]\n",
    "co_occs = co_occs.stack()\n",
    "co_occs.sort_values(ascending=False).head(20)\n",
    "\n",
    "genre = genres[genres.apply(lambda l: \"hard bop\" in l)]\n",
    "sum(genre.apply(lambda gs: \"cool jazz\" in gs)) / len(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31caadb0-88e9-44ac-aae5-906adaaf0e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Type, Optional\n",
    "\n",
    "@dataclass\n",
    "class GenreNode:\n",
    "    name: str\n",
    "    split_name: List[str] = field(default_factory=list)\n",
    "    parents: List[Type[\"GenreNode\"]] = field(default_factory=list)\n",
    "    children: List[Type[\"GenreNode\"]] = field(default_factory=list)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.split_name = self.name.replace(\"-\", \" \").split(\" \")\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.name}: ({len(self.children)}){[c.name for c in self.children]}\" \n",
    "    \n",
    "    def __len__(self):\n",
    "        if not self.children: return 0\n",
    "        return sum(len(child) or 1 for child in self.children)\n",
    "    \n",
    "    def is_supergenre_of(self, node):\n",
    "        # second term is to prevent \"dance pop\" \"pop dance\" infinite loop\n",
    "        return all(tok in node.split_name for tok in self.split_name) and len(self.split_name) < len(node.split_name)\n",
    "    \n",
    "    def remove_children_from_parents(self):       \n",
    "        for parent in self.parents:\n",
    "            for child in self.children:\n",
    "                if child in parent.children:\n",
    "                    parent.children.remove(child)\n",
    "                if parent in child.parents:\n",
    "                    child.parents.remove(parent)\n",
    "            parent.remove_children_from_parents()\n",
    "            \n",
    "    def depth_from_parent(self, parent):\n",
    "        if self == parent: return 0\n",
    "        if not self.parents: return float(\"-inf\")\n",
    "        return max(map(lambda n: n.depth_from_parent(parent), self.parents)) + 1\n",
    "            \n",
    "    def print_tree(self, root=None, indent=0):\n",
    "        print(indent*\"\\t\" + f\"{self.name} ({len(self)})\")\n",
    "        for child in sorted(self.children, key=lambda c: c.depth_from_parent(root), reverse=True):\n",
    "            child.print_tree(root or self, indent+1)\n",
    "            \n",
    "    @staticmethod\n",
    "    def tie_breaker(disputed_child, parents):\n",
    "        # returns must suitable parent for child node. Returns None if unable to find best parent\n",
    "        for i in range(len(disputed_child.split_name)):\n",
    "            trimmed_child_name = \" \".join(disputed_child.split_name[i:])\n",
    "            matches = [parent for parent in parents\n",
    "                       if \" \".join(parent.split_name) == trimmed_child_name]  # Join split name instead of using name. Avoids issues with \"-\"\n",
    "            if matches:\n",
    "                if len(matches) == 1:\n",
    "                    return matches[0]\n",
    "                return None\n",
    "            \n",
    "            \n",
    "def lexical_genre_hierarchy(genres): \n",
    "    def node_depth(node):\n",
    "        if not node.parents: return 0\n",
    "        return max(map(node_depth, node.parents)) + 1\n",
    "    \n",
    "    node_map = {genre: GenreNode(genre) for genre in genres}\n",
    "    nodes = node_map.values()\n",
    "    \n",
    "    # first pass\n",
    "    for node in nodes:\n",
    "        subgenre_nodes = filter(node.is_supergenre_of, nodes)\n",
    "        for subg_n in subgenre_nodes:\n",
    "            if subg_n != node:\n",
    "                node.children.append(subg_n)\n",
    "                subg_n.parents.append(node)\n",
    "\n",
    "    for leaf_node in filter(lambda n: n.parents and not n.children, nodes):\n",
    "        leaf_node.remove_children_from_parents()\n",
    "                 \n",
    "    return node_map \n",
    "\n",
    "\n",
    "genre_series = pd.Series(flatten_series(genres).unique())\n",
    "hierarchy = lexical_genre_hierarchy(genre_series)\n",
    "ranked = sorted(hierarchy.values(), key=len, reverse=True)\n",
    "\n",
    "for node in ranked[:3]:\n",
    "    node.print_tree()                                              \n",
    "\n",
    "for node in ranked[-3:]:\n",
    "    node.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a455b8ea-a9f3-44d0-99f8-bdc7b5921437",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_genres = [n.name for n in ranked[:10]]\n",
    "merged.genres = merged.genres.apply(lambda gs: [g for g in gs if g in top_genres])\n",
    "\n",
    "merged.month = df.endTime - pd.offsets.MonthBegin(0)\n",
    "df.month = df.month.dt.round('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb885af-d940-49a6-9eca-6ecd9b0397c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.plotting.scatter_matrix(adj_matrix)\n",
    "top = adj_matrix.idxmax().head(10)\n",
    "[(gs, adj_matrix[gs[0]][gs[1]]) for gs in top.items()]\n",
    "stacked = adj_matrix.stack()\n",
    "stacked[stacked > 0].sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f13467-e21b-4c92-b84c-f080501e6609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_graph_with_labels(adjacency_matrix):\n",
    "    rows, cols = np.where(adjacency_matrix == 1)\n",
    "    edges = zip(rows.tolist(), cols.tolist())\n",
    "    gr = nx.Graph()\n",
    "    gr.add_edges_from(edges)\n",
    "    nx.draw(gr, labels=adjacency_matrix.index, with_labels=True)\n",
    "    plt.show()\n",
    "    \n",
    "# show_graph_with_labels(adj_matrix)\n",
    "plt.figure(figsize=(25,17))\n",
    "n = 15\n",
    "nx.draw_networkx(nx.from_pandas_adjacency(adj_matrix[:n][:n]), node_size=800, node_color='lightblue', font_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2660294-ba5c-4778-a2aa-ad7f2a85e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_list = genre_adj_list(artist_data.genres)\n",
    "G = nx.Graph()\n",
    "for _idx, genre, neighbors in adj_list.itertuples():\n",
    "    G.add_edges_from([(genre, n) for n in set(neighbors)])\n",
    "    \n",
    "\n",
    "pos = nx.spring_layout(G)    \n",
    "nx.draw_networkx_edge_labels(G, pos)\n",
    "nx.draw(G, pos, edge_color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade9b49-8c2b-47c7-8973-ef97a618ea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_count(merged).head(10)\n",
    "merged.head(10)\n",
    "\n",
    "weighted_genre_count(merged).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4302fb37-2287-462b-8a7e-729c3a56ae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_listens(df, granularity=\"month\"):\n",
    "    df = df.copy()\n",
    "    df.sort_values(by=\"endTime\", ascending=True)\n",
    "    df.endTime = df.endTime - pd.offsets.MonthBegin(0)\n",
    "    df.endTime = df.endTime.dt.round('d')\n",
    "    \n",
    "    known = set()\n",
    "    df[\"new\"] = 0\n",
    "    \n",
    "    # Doesn't account for different songs having same name. Solve using track ids\n",
    "    for idx, track in df[[\"trackName\"]].itertuples():\n",
    "        if track not in known:\n",
    "            known.add(track)\n",
    "            df.at[idx, \"new\"] = 1\n",
    "            \n",
    "    return df.groupby(\"endTime\")[\"new\"].sum()\n",
    "\n",
    "\n",
    "new_listens(df).plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
